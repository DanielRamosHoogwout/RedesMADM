vertex.label.cex=.7)
# The second way to set attributes is to add them to the igraph object.
# Generate colors based on media type:
colrs <- c("gray50", "tomato", "gold")
V(net)$color <- colrs[V(net)$media.type]
# Set node size based on audience size:
V(net)$size <- V(net)$audience.size*0.7
# The labels are currently node IDs.
# Setting them to NA will render no labels:
V(net)$label.color <- "black"
V(net)$label <- NA
# Set edge width based on weight:
E(net)$width <- E(net)$weight/6
#change arrow size and edge color:
E(net)$arrow.size <- .2
E(net)$edge.color <- "gray80"
plot(net)
# We can also override the attributes explicitly in the plot:
plot(net, edge.color="orange", vertex.color="gray50")
# We can also add a legend explaining the meaning of the colors we used:
plot(net)
legend(x=-1.1, y=-1.1, c("Newspaper","Television", "Online News"), pch=21,
col="#777777", pt.bg=colrs, pt.cex=2.5, bty="n", ncol=1)
# Sometimes, especially with semantic networks, we may be interested in
# plotting only the labels of the nodes:
plot(net, vertex.shape="none", vertex.label=V(net)$media,
vertex.label.font=2, vertex.label.color="gray40",
vertex.label.cex=.7, edge.color="gray85")
# Let's color the edges of the graph based on their source node color.
# We'll get the starting node for each edge with "ends()".
edge.start <- ends(net, es=E(net), names=F)[,1]
edge.col <- V(net)$color[edge.start]
plot(net, edge.color=edge.col, edge.curved=.1)
#  ------->> Network Layouts --------
# Network layouts are algorithms that return coordinates for each
# node in a network.
# Let's generate a slightly larger 80-node graph.
net.bg <- sample_pa(80, 1.2)
V(net.bg)$size <- 8
V(net.bg)$frame.color <- "white"
V(net.bg)$color <- "orange"
V(net.bg)$label <- ""
E(net.bg)$arrow.mode <- 0
plot(net.bg)
# You can set the layout in the plot function:
plot(net.bg, layout=layout_randomly)
# Or calculate the vertex coordinates in advance:
l <- layout_in_circle(net.bg)
plot(net.bg, layout=l)
# l is simply a matrix of x,y coordinates (N x 2) for the N nodes in the graph.
# You can generate your own:
l
l <- cbind(1:vcount(net.bg), c(1, vcount(net.bg):2))
plot(net.bg, layout=l)
# This layout is just an example and not very helpful - thankfully
# igraph has a number of built-in layouts, including:
# Randomly placed vertices
l <- layout_randomly(net.bg)
plot(net.bg, layout=l)
# Circle layout
l <- layout_in_circle(net.bg)
plot(net.bg, layout=l)
# 3D sphere layout
l <- layout_on_sphere(net.bg)
plot(net.bg, layout=l)
# The Fruchterman-Reingold force-directed algorithm
# Nice but slow, most often used in graphs smaller than ~1000 vertices.
l <- layout_with_fr(net.bg)
plot(net.bg, layout=l)
# You will also notice that the layout is not deterministic - different runs
# will result in slightly different configurations. Saving the layout in l
# allows us to get the exact same result multiple times.
par(mfrow=c(2,2), mar=c(1,1,1,1))
plot(net.bg, layout=layout_with_fr)
plot(net.bg, layout=layout_with_fr)
plot(net.bg, layout=l)
plot(net.bg, layout=l)
dev.off()
# By default, the coordinates of the plots are rescaled to the [-1,1] interval
# for both x and y. You can change that with the parameter "rescale=FALSE"
# and rescale your plot manually by multiplying the coordinates by a scalar.
# You can use norm_coords to normalize the plot with the boundaries you want.
# Get the layout coordinates:
l <- layout_with_fr(net.bg)
# Normalize them so that they are in the -1, 1 interval:
l <- norm_coords(l, ymin=-1, ymax=1, xmin=-1, xmax=1)
par(mfrow=c(2,2), mar=c(0,0,0,0))
plot(net.bg, rescale=F, layout=l*0.4)
plot(net.bg, rescale=F, layout=l*0.8)
plot(net.bg, rescale=F, layout=l*1.2)
plot(net.bg, rescale=F, layout=l*1.6)
dev.off()
# Another popular force-directed algorithm that produces nice results for
# connected graphs is Kamada Kawai. Like Fruchterman Reingold, it attempts to
# minimize the energy in a spring system.
l <- layout_with_kk(net.bg)
plot(net.bg, layout=l)
# The LGL algorithm is for large connected graphs. Here you can specify a root -
# the node that will be placed in the middle of the layout.
plot(net.bg, layout=layout_with_lgl)
# By default, igraph uses a layout called layout_nicely which selects
# an appropriate layout algorithm based on the properties of the graph.
# Check out all available layouts in igraph:
?igraph::layout_
layouts <- grep("^layout_", ls("package:igraph"), value=TRUE)[-1]
# Remove layouts that do not apply to our graph.
layouts <- layouts[!grepl("bipartite|merge|norm|sugiyama|tree", layouts)]
par(mfrow=c(3,3), mar=c(1,1,1,1))
for (layout in layouts) {
print(layout)
l <- do.call(layout, list(net))
plot(net, edge.arrow.mode=0, layout=l, main=layout) }
dev.off()
-----------------------------------
# * TASK FOR WORKSHOP PARTICIPANTS:
# Plot the Zachary karate club network with four different layouts of your choice.
-----------------------------------
# ------->> Improving network plots --------
plot(net)
# Notice that this network plot is still not too helpful.
# We can identify the type and size of nodes, but cannot see
# much about the structure since the links we're examining are so dense.
# One way to approach this is to see if we can sparsify the network.
hist(links$weight)
mean(links$weight)
sd(links$weight)
# There are more sophisticated ways to extract the key edges,
# but for the purposes of this excercise we'll only keep ones
# that have weight higher than the mean for the network.
# We can delete edges using delete_edges(net, edges)
cut.off <- mean(links$weight)
net.sp <- delete_edges(net, E(net)[weight<cut.off])
plot(net.sp)
# Another way to think about this is to plot the two tie types
# (hyperlik & mention) separately:
E(net)$width <- 2
plot(net, edge.color=c("dark red", "slategrey")[(E(net)$type=="hyperlink")+1],
vertex.color="gray40", layout=layout_in_circle)
# Another way to delete edges:
net.m <- net - E(net)[E(net)$type=="hyperlink"]
net.h <- net - E(net)[E(net)$type=="mention"]
# Plot the two links separately:
par(mfrow=c(1,2))
plot(net.h, vertex.color="orange", main="Tie: Hyperlink")
plot(net.m, vertex.color="lightsteelblue2", main="Tie: Mention")
dev.off()
# Make sure the nodes stay in place in both plots:
par(mfrow=c(1,2),mar=c(1,1,4,1))
l <- layout_with_fr(net)
plot(net.h, vertex.color="orange", layout=l, main="Tie: Hyperlink")
plot(net.m, vertex.color="lightsteelblue2", layout=l, main="Tie: Mention")
dev.off()
# ------->> Interactive plotting with tkplot --------
# R and igraph offer interactive plotting capabilities
# (mostly helpful for small networks)
tkid <- tkplot(net) #tkid is the id of the tkplot
l <- tkplot.getcoords(tkid) # grab the coordinates from tkplot
tk_close(tkid, window.close = T)
plot(net, layout=l)
# ------->> Heatmaps as a way to represent networks --------
# A quick reminder that there are other ways to represent a network:
# Heatmap of the network matrix:
netm <- get.adjacency(net, attr="weight", sparse=F)
colnames(netm) <- V(net)$media
rownames(netm) <- V(net)$media
palf <- colorRampPalette(c("gold", "dark orange"))
heatmap(netm[,17:1], Rowv = NA, Colv = NA, col = palf(20),
scale="none", margins=c(10,10) )
# ------->> Plotting two-mode networks with igraph --------
head(nodes2)
head(links2)
net2
plot(net2)
# This time we will make nodes look different based on their type.
V(net2)$color <- c("steel blue", "orange")[V(net2)$type+1]
V(net2)$shape <- c("square", "circle")[V(net2)$type+1]
V(net2)$label <- ""
V(net2)$label[V(net2)$type==F] <- nodes2$media[V(net2)$type==F]
V(net2)$label.cex=.6
V(net2)$label.font=2
plot(net2, vertex.label.color="white", vertex.size=(2-V(net2)$type)*8)
plot(net2, vertex.label=NA, vertex.size=7, layout=layout_as_bipartite)
# Using text as nodes:
par(mar=c(0,0,0,0))
plot(net2, vertex.shape="none", vertex.label=nodes2$media,
vertex.label.color=V(net2)$color, vertex.label.font=2,
vertex.label.cex=.95, edge.color="gray70",  edge.width=2)
dev.off()
# ================ 6. Network and node descriptives ================
# Density
# The proportion of present edges from all possible ties.
edge_density(net, loops=F)
ecount(net)/(vcount(net)*(vcount(net)-1)) #for a directed network
# Reciprocity
# The proportion of reciprocated ties (for a directed network).
reciprocity(net)
dyad_census(net) # Mutual, asymmetric, and null node pairs
2*dyad_census(net)$mut/ecount(net) # Calculating reciprocity
# Transitivity
# global - ratio of triangles (direction disregarded) to connected triples
# local - ratio of triangles to connected triples each vertex is part of
transitivity(net, type="global")  # net is treated as an undirected network
transitivity(as.undirected(net, mode="collapse")) # same as above
transitivity(net, type="local")
triad_census(net) # for directed networks
# Triad types (per Davis & Leinhardt):
#
# 003  A, B, C, empty triad.
# 012  A->B, C
# 102  A<->B, C
# 021D A<-B->C
# 021U A->B<-C
# 021C A->B->C
# 111D A<->B<-C
# 111U A<->B->C
# 030T A->B<-C, A->C
# 030C A<-B<-C, A->C.
# 201  A<->B<->C.
# 120D A<-B->C, A<->C.
# 120U A->B<-C, A<->C.
# 120C A->B->C, A<->C.
# 210  A->B<->C, A<->C.
# 300  A<->B<->C, A<->C, completely connected.
# Diameter (longest geodesic distance)
# Note that edge weights are used by default, unless set to NA.
diameter(net, directed=F, weights=NA)
diameter(net, directed=F)
diam <- get_diameter(net, directed=T)
diam
# Note: vertex sequences asked to behave as a vector produce numeric index of nodes
class(diam)
as.vector(diam)
# Color nodes along the diameter:
vcol <- rep("gray40", vcount(net))
vcol[diam] <- "gold"
ecol <- rep("gray80", ecount(net))
ecol[E(net, path=diam)] <- "orange"
# E(net, path=diam) finds edges along a path, here 'diam'
plot(net, vertex.color=vcol, edge.color=ecol, edge.arrow.mode=0)
# Node degrees
# 'degree' has a mode of 'in' for in-degree, 'out' for out-degree,
# and 'all' or 'total' for total degree.
deg <- degree(net, mode="all")
plot(net, vertex.size=deg*3)
hist(deg, breaks=1:vcount(net)-1, main="Histogram of node degree")
# Degree distribution
deg.dist <- degree_distribution(net, cumulative=T, mode="all")
plot( x=0:max(deg), y=1-deg.dist, pch=19, cex=1.2, col="orange",
xlab="Degree", ylab="Cumulative Frequency")
# Centrality & centralization
# Centrality functions (vertex level) and centralization functions (graph level).
# The centralization functions return "res" - vertex centrality, "centralization",
# and "theoretical_max" - maximum centralization score for a graph of that size.
# The centrality functions can run on a subset of nodes (set with the "vids" parameter)
# Degree (number of ties)
degree(net, mode="in")
centr_degree(net, mode="in", normalized=T)
# Closeness (centrality based on distance to others in the graph)
# Inverse of the node's average geodesic distance to others in the network
closeness(net, mode="all", weights=NA)
centr_clo(net, mode="all", normalized=T)
# Eigenvector (centrality proportional to the sum of connection centralities)
# Values of the first eigenvector of the graph adjacency matrix
eigen_centrality(net, directed=T, weights=NA)
centr_eigen(net, directed=T, normalized=T)
# Betweenness (centrality based on a broker position connecting others)
# (Number of geodesics that pass through the node or the edge)
betweenness(net, directed=T, weights=NA)
edge_betweenness(net, directed=T, weights=NA)
centr_betw(net, directed=T, normalized=T)
-----------------------------------
# * TASK FOR WORKSHOP PARTICIPANTS:
# Compute the degree, closeness, eigenvector, and betweenness centrality of
# the actors in the Zachary karate club network. Plot the network, sizing the
# nodes based on the different centrality types.
-----------------------------------
# Hubs and authorities
# The hubs and authorities algorithm developed by Jon Kleinberg was initially used
# to examine web pages. Hubs were expected to contain catalogues with a large number
# of outgoing links; while authorities would get many incoming links from hubs,
# presumably because of their high-quality relevant information.
hs <- hub_score(net, weights=NA)$vector
as <- authority_score(net, weights=NA)$vector
par(mfrow=c(1,2))
plot(net, vertex.size=hs*50, main="Hubs")
plot(net, vertex.size=as*30, main="Authorities")
dev.off()
gl <- graph_from_literal(a-b-c-d-e-f, a-g-h-b, h-e:f:i, j)
plot(gl)
# Set the working directory to the folder containing the workshop files:
setwd("../../Desktop/Redes Sociales y Economicas/data/")
getwd()
# Set the working directory to the folder containing the workshop files:
setwd("../../Desktop/Redes Sociales y Economicas/data/")
getwd()
# Set the working directory to the folder containing the workshop files:
setwd("../../Desktop/Redes Sociales y Economicas/data/")
gf <- graph_from_data_frame(d=data, directed = T)
knitr::opts_chunk$set(fig.align="center", echo=TRUE, warning=FALSE, message=FALSE,autodep = TRUE,cache=FALSE)
library(knitr)
library(printr)
library(igraph)
data <- read.table("./data/facebook_sample_anon.txt")
head(data)
gf <- graph_from_data_frame(d=data, directed = F)
gf <- graph_from_data_frame(d=data, directed = T)
hs <- hub_score(gf, weights=NA)$vector
as <- authority_score(gf, weights=NA)$vector
plot(gf, vertex.size=hs*50, main="Hubs")
plot(gf, vertex.size=as*30, main="Authorities")
install.packages("networkR")
library(networkR)
# data <- read.table("facebook_sample_anon.txt")
# head(data)
# gf_d <- graph_from_data_frame(d=data, directed = T)
kmax<-6 # 6 iteraciones
gf_d_mtx <- as_adjacency_matrix(gf)
op<-hits(gf_d_mtx,kmax)
op
str(op$authorities)
str(op$hubs)
str(op$authorities)-as
as
V(gf)$degree <- degree(gf)
V(gf)$closeness <- closeness(gf)
V(gf)$betweenness <- betweenness(gf)
knitr::opts_chunk$set(fig.align="center", echo=TRUE, warning=FALSE, message=FALSE,autodep = TRUE,cache=FALSE)
library(knitr)
library(printr)
library(igraph)
data <- read.table("./data/facebook_sample_anon.txt")
head(data)
gf <- graph_from_data_frame(d=data, directed = F)
set.seed(2020)
longitud <- length(V(gf))#Numero de Nodos iniciales
new.gf <- gf #Copiamos gf
vector.connectedness <- double(1000) #Inicializamos vectores
vector.fraction.network <- double(1000)
for(x in 1:1000){
#Escogemos nodos aleatorios
nodos = sample(V(new.gf),round(0.001*longitud), replace = FALSE)
length(V(new.gf))
#Eliminamos los nodos escogidos anteriormente
new.gf<- igraph::delete.vertices(new.gf, nodos)
length(V(new.gf))
vector.connectedness[x] <- components(new.gf)$no
vector.fraction.network[x] <- max(components(new.gf)$csize)/sum(components(new.gf)$csize)
}
mean(vector.connectedness)
mean(vector.fraction.network)
V(gf)$degree <- degree(gf)
V(gf)$closeness <- closeness(gf)
V(gf)$betweenness <- betweenness(gf)
max_degree <- sort(V(gf)$degree, decreasing = TRUE)[1:4]
central_v_degree <- V(gf)[V(gf)$degree %in% max_degree]
# Eliminamos los nodos más centrales
n_gf <- delete_vertices(gf, central_v_degree)
components(n_gf)$no
max(components(n_gf)$csize) / sum(components(n_gf)$csize)
V(gf)$closeness <- closeness(gf)
max_degree3 <- sort(V(gf)$closeness, decreasing = TRUE)[1:4]
central_v_degree3 <- V(gf)[V(gf)$closeness %in% max_degree3]
# Eliminamos los nodos más centrales
n_gf3 <- delete_vertices(gf, central_v_degree3)
components(n_gf3)$no
max(components(n_gf3)$csize) / sum(components(n_gf3)$csize)
V(gf)$betweenness <- betweenness(gf)
max_degree2 <- sort(V(gf)$betweenness, decreasing = TRUE)[1:4]
central_v_degree2 <- V(gf)[V(gf)$betweenness %in% max_degree2]
# Eliminamos los nodos más centrales
n_gf2 <- delete_vertices(gf, central_v_degree2)
components(n_gf2)$no
max(components(n_gf2)$csize) / sum(components(n_gf2)$csize)
V(gf)$pageRank <- page_rank(gf,directed=F)$vector
vertices <- vector(,length(V(gf)))
for (x in 1:length(V(gf))){
vertices[x] <- V(gf)$pageRank[[x]]
}
max_degree4 <- sort(vertices, decreasing = TRUE)[1:4]
central_v_degree4 <- V(gf)[V(gf)$pageRank %in% max_degree4]
# Eliminamos los nodos más centrales
n_gf4 <- delete_vertices(gf, central_v_degree4)
components(n_gf4)$no
max(components(n_gf4)$csize) / sum(components(n_gf4)$csize)
data <- read.table("./data/facebook_sample_anon.txt")
head(data)
gf <- graph_from_data_frame(d=data, directed = F)
data <- read.table("../../../Xarxes Socials i Econòmiques/Exercicis/webPageLinks.txt")
data
G <- graph_from_data_frame(d=data, directed = T)
library(igraph)
G <- graph_from_data_frame(d=data, directed = T)
G
plot(G)
G
M <- matrix(data)
M
data
View(data)
M <- matrix(data)
View(M)
View(M)
M <- as_adjacency_matrix(G)
M
data <- read.table("../../../Xarxes Socials i Econòmiques/Exercicis/webPageLinks.txt")
data
G <- graph_from_data_frame(d=data, directed = T)
plot(G)
M <- matrix(data)
?matrix
M <- as_adjacency_matrix(G)
M
data
View(data)
M <- matrix(data,nrow=100,ncol=100,byrow=TRUE)
M
View(M)
?read.table
data <- read.table("../../../Xarxes Socials i Econòmiques/Exercicis/webPageLinks.txt",sep=" ")
data
data <- read.table("../../../Xarxes Socials i Econòmiques/Exercicis/webPageLinks.txt")
data
View(data)
M <- data.matrix(data)
View(M)
K <- t(M) %*% M
tt <- M %*% t(M)
MIdg <- max(degree(G,mode="in"))
MOdg <- max(degree(G,mode="out"))
tt
View(tt)
MaM <- as_adjacency_matrix(M)
G <- graph(M)
G <- graph_from_adjacency_matrix(M)
G
plat(G)
plot(G)
MIdg <- max(degree(G,mode="in"))
MOdg <- max(degree(G,mode="out"))
gamma <- 1/(min(MIdg,MOdg))
# K---------------------------------------------------------------------
Kgamma <- K %*% solve(diag(8) - gamma*K)
dims(M)
# K---------------------------------------------------------------------
Kgamma <- K %*% solve(diag(100) - gamma*K)
Kgamma_results = data.frame()
for (i in 1:nrow(Kgamma)){
Kgamma_newsum=sum(Kgamma[i,])
Kgamma_results=rbind(Kgamma_results,Kgamma_newsum)
rm(Kgamma_newsum)
}
Kgamma_results
dimnames(data)
dimnames[[1]]
dimnames[1]
str(data)
colnames(data)
Kgamma_results <- Kgamma_results %>%
mutate(V=colnames(data), .before=X2.33333333333333)
library(tidyverse)
Kgamma_results <- Kgamma_results %>%
mutate(V=colnames(data), .before=X2.33333333333333)
View(Kgamma_results)
ncol(data)
data <- read.table("../../../Xarxes Socials i Econòmiques/Exercicis/webPageLinks.txt")
M <- data.matrix(data)
G <- graph_from_adjacency_matrix(M)
K <- t(M) %*% M
tt <- M %*% t(M)
MIdg <- max(degree(G,mode="in"))
MOdg <- max(degree(G,mode="out"))
gamma <- 1/(min(MIdg,MOdg))
# K---------------------------------------------------------------------
Kgamma <- K %*% solve(diag(ncol(100)) - gamma*K)
# K---------------------------------------------------------------------
Kgamma <- K %*% solve(diag(ncol(data)) - gamma*K)
Kgamma_results = data.frame()
for (i in 1:nrow(Kgamma)){
Kgamma_newsum=sum(Kgamma[i,])
Kgamma_results=rbind(Kgamma_results,Kgamma_newsum)
rm(Kgamma_newsum)
}
Kgamma_results <- Kgamma_results %>%
mutate(V=colnames(data), .before=X2.33333333333333)
View(Kgamma_results)
Tgamma <- tt %*% solve(diag(ncol(data)) - gamma*tt)
Tgamma_results = data.frame()
for (i in 1:nrow(Tgamma)){
Tgamma_newsum=sum(Tgamma[i,])
Tgamma_results=rbind(Tgamma_results,Tgamma_newsum)
rm(Tgamma_newsum)
}
Tgamma_results <- Tgamma_results %>%
mutate(V=c("n5","n1","n2","n6","n3","n7","n4","n8"), .before=X.6)
Tgamma_results
Tgamma <- tt %*% solve(diag(ncol(data)) - gamma*tt)
Tgamma_results = data.frame()
for (i in 1:nrow(Tgamma)){
Tgamma_newsum=sum(Tgamma[i,])
Tgamma_results=rbind(Tgamma_results,Tgamma_newsum)
rm(Tgamma_newsum)
}
Tgamma_results <- Tgamma_results %>%
mutate(V=colnames(data), .before=X0)
View(Tgamma_results)
data1 <- read_tsv(k, col_names=F,
n_max = 10000, skip=0)
library(tidyverse)
data1 <- read_tsv(k, col_names=F,
n_max = 10000, skip=0)
data1 <- read_tsv("data/combined_data_1.txt", col_names=F,
n_max = 10000, skip=0)
